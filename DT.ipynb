{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db092f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ced557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Load Dataset ---\n",
    "df = pd.read_csv(\"C:/Users/DELL/Desktop/MSc/1st Sem/AML/Loan_Default - Copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Data Exploration ---\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values summary\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_table = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage\": missing_percent\n",
    "})\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_table[missing_table[\"Missing Values\"] > 0])\n",
    "\n",
    "# Missing values heatmap\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5488cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "sns.countplot(x=\"Status\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Class Distribution (Target Variable)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop identifier columns ---\n",
    "if \"ID\" in df.columns:\n",
    "    print(\"Dropping ID column...\")\n",
    "    df = df.drop(columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (numerical features)\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Pre-Processing ---\n",
    "# Separate numeric and categorical columns\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numeric\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# Impute categorical\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_array = encoder.fit_transform(df[cat_cols])\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(cat_cols), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8afa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = pd.concat([df[num_cols].drop(\"Status\", axis=1, errors=\"ignore\"), encoded_df], axis=1)\n",
    "y = df[\"Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Status in X?\", \"Status\" in X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659115b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE on training set (no scaling for tree models)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Class distribution after SMOTE\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=y_train_res, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution After SMOTE (Training Data)\")\n",
    "plt.xlabel(\"Loan Status (0 = Non-default, 1 = Default)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdc9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6a: Baseline Model ---\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_nm, y_train_nm)\n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Baseline Decision Tree Results:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6b: Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, 9],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3, scoring=\"f1\", n_jobs=-1, verbose=2\n",
    ")\n",
    "grid_dt.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Parameters:\", grid_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_best = best_dt.predict(X_test)\n",
    "\n",
    "print(\"Tuned Decision Tree Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: ROC Curve ---\n",
    "y_proba = best_dt.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f'Decision Tree (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Decision Tree\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 8: Visualize Tree (Optional) ---\n",
    "plt.figure(figsize=(16,8))\n",
    "plot_tree(best_dt, filled=True, feature_names=X.columns, class_names=[\"Non-default\",\"Default\"], max_depth=3)\n",
    "plt.title(\"Decision Tree (First 3 Levels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d554403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "y_shuffled = shuffle(y, random_state=42)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X, y_shuffled, test_size=0.2, stratify=y_shuffled, random_state=42\n",
    ")\n",
    "\n",
    "dt_test = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt_test.fit(X_train_s, y_train_s)\n",
    "print(\"Accuracy with shuffled target:\", dt_test.score(X_test_s, y_test_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5086000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18387e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Use the preprocessed X and y ---\n",
    "# Shuffle the target only\n",
    "y_shuf = shuffle(y, random_state=42).reset_index(drop=True)\n",
    "X_shuf = X.reset_index(drop=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_shuf, y_shuf, test_size=0.2, stratify=y_shuf, random_state=42\n",
    ")\n",
    "\n",
    "# Train a weak Decision Tree\n",
    "dt_test = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt_test.fit(X_train_s, y_train_s)\n",
    "\n",
    "print(\"Accuracy with shuffled target:\", dt_test.score(X_test_s, y_test_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98015b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "suspicious = []\n",
    "for col in X.columns:\n",
    "    try:\n",
    "        auc = roc_auc_score(y, X[col])\n",
    "        if auc > 0.95 or auc < 0.05:  # very strong predictor\n",
    "            suspicious.append((col, auc))\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(\"Suspicious columns:\", suspicious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "print(\"LogReg test accuracy:\", lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate rows in dataset:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e465131",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_shallow = DecisionTreeClassifier(random_state=42, max_depth=2)\n",
    "dt_shallow.fit(X_train_res, y_train_res)\n",
    "print(\"Shallow tree test accuracy:\", dt_shallow.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "\n",
    "# --- Cross-validation ---\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)   # change model here\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Learning curve ---\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    model, X, y, cv=5, scoring=\"accuracy\",\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label=\"Training Accuracy\")\n",
    "plt.plot(train_sizes, val_mean, 'o-', label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
