{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37256e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic checks for leakage / perfect predictors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce833890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data (adjust path if needed) ---\n",
    "df = pd.read_csv(\"C:/Users/DELL/Desktop/MSc/1st Sem/AML/Loan_Default - Copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6549b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (49999, 34)\n",
      "Columns: ['ID', 'year', 'loan_limit', 'Gender', 'approv_in_adv', 'loan_type', 'loan_purpose', 'Credit_Worthiness', 'open_credit', 'business_or_commercial', 'loan_amount', 'rate_of_interest', 'Interest_rate_spread', 'Upfront_charges', 'term', 'Neg_ammortization', 'interest_only', 'lump_sum_payment', 'property_value', 'construction_type', 'occupancy_type', 'Secured_by', 'total_units', 'income', 'credit_type', 'Credit_Score', 'co-applicant_credit_type', 'age', 'submission_of_application', 'LTV']\n"
     ]
    }
   ],
   "source": [
    "# quick head & shapes\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist()[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e7ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target 'Status' dtype and unique values: int64 [1 0]\n",
      "\n",
      "Missing value counts (top 20):\n",
      "Upfront_charges              13287\n",
      "Interest_rate_spread         12281\n",
      "rate_of_interest             12209\n",
      "dtir1                         8072\n",
      "property_value                5104\n",
      "LTV                           5104\n",
      "income                        3008\n",
      "loan_limit                    1109\n",
      "approv_in_adv                  277\n",
      "age                             72\n",
      "submission_of_application       72\n",
      "Neg_ammortization               40\n",
      "loan_purpose                    38\n",
      "term                            16\n",
      "year                             0\n",
      "ID                               0\n",
      "business_or_commercial           0\n",
      "open_credit                      0\n",
      "lump_sum_payment                 0\n",
      "interest_only                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing and target check\n",
    "print(\"\\nTarget 'Status' dtype and unique values:\", df['Status'].dtype, df['Status'].unique()[:10])\n",
    "print(\"\\nMissing value counts (top 20):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5071575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess same way as notebook (impute + encode) but DO NOT drop anything yet\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4370ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fdb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categoricals (if none, encoded_df will be empty)\n",
    "if len(cat_cols) > 0:\n",
    "    encoder = OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\")\n",
    "    encoded_array = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n",
    "else:\n",
    "    encoded_df = pd.DataFrame(index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae31ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape: (49999, 50) y shape: (49999,)\n",
      "Is 'Status' in X columns? False\n"
     ]
    }
   ],
   "source": [
    "# Build X,y but KEEP columns intact for diagnostics (we will drop identifiers later if needed)\n",
    "X = pd.concat([df[num_cols].drop(\"Status\", axis=1, errors=\"ignore\"), encoded_df], axis=1)\n",
    "y = df['Status']\n",
    "\n",
    "print(\"\\nX shape:\", X.shape, \"y shape:\", y.shape)\n",
    "print(\"Is 'Status' in X columns?\", \"Status\" in X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ce21fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with very high cardinality (possible IDs) -> drop or investigate:\n",
      "['ID']\n"
     ]
    }
   ],
   "source": [
    "# 1) Check for columns with near-unique values (possible ID columns)\n",
    "n = len(X)\n",
    "id_like = [c for c in X.columns if X[c].nunique() >= 0.95 * n]\n",
    "print(\"\\nColumns with very high cardinality (possible IDs) -> drop or investigate:\")\n",
    "print(id_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2f1c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/test shapes: (39999, 50) (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "# 2) Check if any column exactly matches the target on the test set later (we'll split first)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"\\nTrain/test shapes:\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bea7decb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index overlap between train & test: 0\n"
     ]
    }
   ],
   "source": [
    "# 3) Quick overlap check of indices (should be zero)\n",
    "index_overlap = len(set(X_train.index).intersection(set(X_test.index)))\n",
    "print(\"Index overlap between train & test:\", index_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38ae7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled row-level overlap (train vs test) among 5000 rows: 0 (should be 0)\n"
     ]
    }
   ],
   "source": [
    "# 4) Quick row overlap check using hashing on a sample if dataset large\n",
    "sample_size = min(5000, len(X_train))\n",
    "sample_train = X_train.sample(sample_size, random_state=42)\n",
    "sample_test = X_test.sample(min(5000, len(X_test)), random_state=42)\n",
    "train_tuples = set(map(tuple, sample_train.values))\n",
    "test_tuples = set(map(tuple, sample_test.values))\n",
    "overlap_sample = len(train_tuples.intersection(test_tuples))\n",
    "print(f\"Sampled row-level overlap (train vs test) among {sample_size} rows: {overlap_sample} (should be 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412e4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfect predictors (AUC ~1 or exact match) on test set (if any):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 5) Check whether any single feature perfectly predicts y on the test set (AUC=1.0 or exact match)\n",
    "perfect_predictors = []\n",
    "for col in X.columns:\n",
    "    # skip if constant\n",
    "    if X_test[col].nunique() <= 1:\n",
    "        continue\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, X_test[col])\n",
    "        if np.isclose(auc, 1.0) or np.isclose(auc, 0.0):\n",
    "            perfect_predictors.append((col, float(auc)))\n",
    "    except Exception:\n",
    "        # if not numeric, try exact match\n",
    "        try:\n",
    "            if X_test[col].equals(y_test):\n",
    "                perfect_predictors.append((col, \"exact_match\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print(\"\\nPerfect predictors (AUC ~1 or exact match) on test set (if any):\")\n",
    "print(perfect_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfdac82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) If any perfect predictor found, print its first 20 values vs target to inspect\n",
    "if perfect_predictors:\n",
    "    for col, val in perfect_predictors:\n",
    "        print(f\"\\nInspecting column: {col}, value={val}\")\n",
    "        print(pd.DataFrame({col: X_test[col].head(20), \"y_test\": y_test.head(20)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdde0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top numeric correlations with target (abs):\n",
      "credit_type_EQUI                     0.610473\n",
      "lump_sum_payment_not_lpsm            0.172626\n",
      "Neg_ammortization_not_neg            0.169903\n",
      "co-applicant_credit_type_EXP         0.147359\n",
      "credit_type_EXP                      0.134748\n",
      "credit_type_CRIF                     0.124802\n",
      "submission_of_application_to_inst    0.119259\n",
      "LTV                                  0.107309\n",
      "Upfront_charges                      0.096680\n",
      "property_value                       0.095971\n",
      "business_or_commercial_nob/c         0.083461\n",
      "loan_type_type2                      0.083461\n",
      "Gender_Joint                         0.077803\n",
      "dtir1                                0.076011\n",
      "income                               0.065698\n",
      "loan_limit_ncf                       0.053913\n",
      "Gender_Sex Not Available             0.053695\n",
      "Interest_rate_spread                 0.047940\n",
      "Region_south                         0.045702\n",
      "approv_in_adv_pre                    0.044530\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 7) Print top 10 correlations with target (numerical only)\n",
    "correlations = X_test.select_dtypes(include=[np.number]).corrwith(y_test).abs().sort_values(ascending=False)\n",
    "print(\"\\nTop numeric correlations with target (abs):\")\n",
    "print(correlations.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63499a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, learning_curve, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Shuffled Target Test\n",
    "def shuffled_target_test(model, X_train, y_train, X_test, y_test):\n",
    "    y_shuffled = np.random.permutation(y_train)\n",
    "    model.fit(X_train, y_shuffled)\n",
    "    acc = model.score(X_test, y_test)\n",
    "    print(f\"Accuracy with shuffled target: {acc:.4f}\")\n",
    "\n",
    "# 2. Shallow Tree Test (only for tree-based models)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def shallow_tree_test(X_train, y_train, X_test, y_test):\n",
    "    dt = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    acc = dt.score(X_test, y_test)\n",
    "    print(f\"Shallow tree test accuracy: {acc:.4f}\")\n",
    "\n",
    "# 3. Cross-validation\n",
    "def cross_validation_test(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "# 4. Learning Curve\n",
    "def plot_learning_curve(model, X, y, title=\"Learning Curve\"):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
